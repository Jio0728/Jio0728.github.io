---
title: Variational Autoencoder
use_math: true
comments: true
published: true
---

### contents:
1. Variational AutoEncoder의 의미
2. 논문 설명

# 1. Variational Autoencoder의 의미

Variational Autoencoder 논문을 살펴보면, 타 딥러닝 논문에 비해 복잡하게 통계 위주로 내용이 전개됩니다. 이를 바로 이해하고, 직관적으로 받아들이는 것은 어려우므로 이번 장에서는 VAE의 의미에 대해서 살펴보고 다음 장에서 자세한 수식과 함께 설명하도록 하겠습니다.
이 장은 아래 블로그를 한 번 더 정리하여 작성하였습니다. 아래 블로그에 더욱 자세히 작성되어 있으니 의미를 이해하고 싶으신 분들은 참고하시길 바랍니다.
[Variational Autoencoder의 의미](https://gaussian37.github.io/dl-concept-vae/)
<br>
<br>
VAE의 처음 시작은 **2D random noise에서 원하는 사진을 얻을 수 있느냐?** 라는 질문에서 시작합니다.
<br>
<img width="712" alt="스크린샷 2022-09-19 오후 9 53 51" src="https://user-images.githubusercontent.com/87808237/191021911-30cfeb40-995e-4045-81ed-8943254d8bca.png">
<br>
한 픽셀이 0부터 256까지의 값을 가질 수 있다고 했을 때, 위 random noise가 가질 수 있는 이미지의 경우의 수는 $256^{Height\ast Width \ast 3(RGB)}$와 같습니다. 즉, 랜덤 노이즈를 그렸을 때, 그것이 내가 원하는 특정 이미지일 확률은 $\frac{1}{256^{Height\ast Width \ast 3(RGB)}}$입니다. 거의 불가능에 가깝습니다.   
그래서 VAE는 특정 이미지를 생성하기 쉬운 어떤 **분포**를 만드는 것을 목표합니다.
<br>
<br>
예를 들어, 우리가 비행기 사진을 어떤 분포로 표현한다고 가정합시다. 
<br>
<img width="696" alt="스크린샷 2022-09-19 오후 10 08 54" src="https://user-images.githubusercontent.com/87808237/191024795-77fb3814-c04f-4cfd-8bef-c9387c9addd8.png">
<br>
위 사진을 분포로 표현한다면, 다음과 같을 것입니다.   
위 사진에서 빨간 동그라미가 위치한 곳은 하늘이 그려져있습니다. 즉, 해당 부분 픽셀값의 분포는 파란색 주위로 밀집되어 있을 것입니다. 반면에, 노란 동그라미가 위치한 곳은 비행기가 그려져 있습니다. 때문에, 해당 부분의 픽셀값의 분포는 회색 주위로 밀집되어 있을 것입니다.    
이와 비슷하게 하늘 중앙에 비행기가 있는 사진들로 이루어진 데이터셋을 VAE 모델이 학습한다면 VAE는 사진의 가장자리(하늘)에 위치한 픽셀들의 값은 파란색 주위로 밀집되어 있고, 사진의 중앙(비행기)에 위치한 픽셀들의 값은 회색 주위로 밀집되어 있다는 그러한 **분포**를 학습하게 될 것입니다.   
그리고, **해당 분포에서 랜덤 노이즈를 뽑아낸다면** 우리는 훨씬 높은 확률로 우리가 원하는 이미지를 생성할 수 있게 됩니다.   
<br>
<br>
위 예시에서 설명한 사진의 특성을 우리는 latent variable이라고 부릅니다. 그리고 VAE는 latent variable의 학습을 목표합니다.
<br>
<img width="845" alt="스크린샷 2022-09-19 오후 10 14 08" src="https://user-images.githubusercontent.com/87808237/191025588-e577c4d4-17f3-403a-9506-9c501b943054.png">
<br>
그리고 해당 분포에서 랜덤 노이즈를 뽑아내어 새로운 이미지를 생성할 수 있게 됩니다.
<br>
<img width="873" alt="스크린샷 2022-09-19 오후 10 14 45" src="https://user-images.githubusercontent.com/87808237/191025730-9446b888-341e-4024-9adb-f6967c4f6531.png">
<br>
<br>
VAE는 Encoder 부분에서 input이미지를 토대로 latent variable을 생성하도록 학습합니다. 여기서 중요한 특성이 하나 있습니다. 바로, VAE는 latent variable을 표현해주는 **$\mu$와 $\sigma$를 생성**한다는 것입니다. 이는 gradient descent를 가능케 만들기 위함입니다. 자세한 설명은 뒤에서 하도록 하겠습니다.
<br>
<img width="853" alt="스크린샷 2022-09-19 오후 10 16 13" src="https://user-images.githubusercontent.com/87808237/191026013-08c2dcd7-e830-45dd-b91e-ae696ca42362.png">



<br>
# 2. 논문 설명
## 2-1. Introduction
논문의 목적은 Intractable한 사후분포를 갖는 continuous latent variables와 parameters를 추론하는 것이다. 해당 추론에는 Variational Bayesian(VB) 접근이 쓰일 수 있다. 하지만 VB 접근 중 흔히 쓰이는 mean-field 접근방식은 사후분포의 근삿값을 필요로 하는데, 현업에서는 그것마저 구하기 어려울 때가 많다.   
때문에 해당 논문에서는 **reparameterization of the variational lower bound**를 통해 미분가능하고 unbiased한 lower bound의 estimator를 구하는 방식을 제안한다. 해당 모델은 SGVB라고 불리고, continuous latent variable, Parameter를 가진 모델에서 사후분포를 추론하는데 사용된다.   
특히, 각 데이터포인트마다 continuous latent variable을 가진 iid 데이터셋에서는 Auto-Encoding VB(AEVB)를 활용하여 사후분포를 추론할 수 있다고 얘기한다. 해당 방식으로 사후분포 추론이 가능하다면 iterative training과 같은 expensive 방법을 쓰지 않고 parameter learning을 할 수 있게 된다.   
이 때, neural network가 recognition model에 사용되는 경우를 Variational Auto-Encoder라고 부른다.

<br>
* * *
<br>
출처:
https://gaussian37.github.io/dl-concept-vae/
https://velog.io/@changdaeoh/vaereview
