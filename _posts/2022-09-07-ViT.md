---
title: Encoder와 ViT 기본 개념 정리
use_math: true
comment: true
published: false
---

### content
1. Encoder
  a. Encoder의 입력: Embedding & Positional Encoding
  b. Residual Connection
  c. Feed-forward layer
  d. Layer Normalization
2. ViT
3. ViT for face recognition
<br>
이번 게시글의 주제는 ViT이다. 때문에 Encoder에 대해서는 간략하게만 집고, ViT 내용으로 바로 넘어가도록 하겠다.

## 1. Encoder
Transformer는 Encoder와 Decoder로 이루어져있다. 이 중 Encoder는 다음의 구조를 가지고 있다.
![1_UKE4mej2zSci-CoRYKb3uQ](https://user-images.githubusercontent.com/87808237/188880192-b01a45b6-6262-4b65-b937-01fd227f7928.png)

### a. Encoder의 입력: Embedding & Positional Encoding
Encoder는 Embedding과 Positional Encoding의 합이 입력값으로 들어간다. 문장의 각 단어를 하나씩 처리하는 RNN과 달리 Transformer는 단어들을 병렬적으로 처리하기 때문에, input 문장의 단어의 위치 정보(순서)를 잃어버린다. 이를 보완하기 위해서, 각 단어의 순서를 나타내는 positional encoding이 들어간다.   
<br>
Positional Encoding은 다음과 같은 조건을 만족해야 한다.
1. 각 단어/time step애 대해서 유일한 encoding을 출력해야 한다.
2. encoding의 값의 상한선과 하한선이 정해져있어야한다.
3. 간격이 동일하다면, 위치와 관계 없이 encoding사이의 간격 또한 동일해야 한다. 또는, 문장의 길이가 늘어나더라도 encoding 값은 변경되면 안 된다. (consistency across sentences)
<br>
해당 조건을 만족하는 Encoding 방법 중 하나는 **Sinusoidal Position Encoding** 이다. 해당 Encoding 공식은 아래와 같다.
<img width="746" alt="스크린샷 2022-09-07 오후 9 54 35" src="https://user-images.githubusercontent.com/87808237/188883411-06867098-07c5-4eb1-8909-9f436cf22d3d.png">
Positional Encoding에 대한 더욱 자세한 사항은 아래 블로그를 참고하자. 아주 잘 정리되어 있다.
https://www.blossominkyung.com/deeplearning/transfomer-positional-encoding

Input 행렬의 각 단어는 d차원의 벡터로 임베딩 된다. 각 단어는 Embedding matrix의 각 행을 이루게 되므로, Embedding matrix는 n\*d 차원이다. (n: 단어의 개수)   
Positional Embedding은 Embedding Matrix와 차원을 맞춰서 생성된다. 즉, 마찬가지로 n\*d차원이다. 이 때 Positional Encodding의 각 행은 Embedding Matrix에서 대응되는 행이 가리키는 단어의 Positional encoding vector이다. 이렇게 생성된 두 matrix는 summation 되어 Encoder의 입력으로 들어간다.

### b. Residual Connection
Encoder 내부에서는 컴퓨터 비전의 ResNet에서 쓰인 개념인 Residual Connection이 들어가있다. 즉, Multi-head Attention에 들어가는 입력값과, Multi-head Attention의 결과 출력값이 합해져서 다음 단계로 넘어가게 된다.

### c. Feed-forward layer
Feed-forward layer는 우리가 아는 fc layer와 동일한 것이다. ReLU 함수를 포함한 2개의 layer로 구성되어 있다.

### d. Layer Normalization
해당 층은 훈련을 안정적으로 하기 위해 들어가있다.
<br>
<br>
## 2. ViT
다음은 ViT에 대해 정리하겠다. ViT의 구조는 다음과 같다. 해당 구조 이미지에 이 블로그에서 설명할 개념들이 모두 들어가있다.
![0](https://user-images.githubusercontent.com/87808237/188885307-8f0ced1d-0c13-4c94-bb9d-0ae61ddc3b09.png)



* * *
Reference:   
https://moon-walker.medium.com/transformer-%EB%B6%84%EC%84%9D-2-transformer%EC%9D%98-encoder-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-1edecc2ad5d4
https://www.blossominkyung.com/deeplearning/transfomer-positional-encoding
